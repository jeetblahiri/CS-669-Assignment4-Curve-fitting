# -*- coding: utf-8 -*-
"""Polynomial fitting_Q1- Assignment4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jBm0-OpesZuDamECVxM-g60AWehZ0cei

Training data size=10, Test data size=3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:10], Y[:10], test_size=3, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""Training data size= 50
Test data size= 21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:50], Y[:50], test_size=21, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""Training data size = 100
Test data size = 43
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:100], Y[:100], test_size=43, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""Complete training set"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=429, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""# With regularisation

## No. of training set data=10

alpha=0.01
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:10], Y[:10], test_size=3, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.01))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""alpha = 0.05"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:10], Y[:10], test_size=3, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.05))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""alpha=0.1"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:10], Y[:10], test_size=3, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""alpha=1"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:10], Y[:10], test_size=3, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""## No of training sets in data = 50, test = 21

### alpha = 0.01


"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:50], Y[:50], test_size=21, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.01))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 0.05"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:50], Y[:50], test_size=21, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.05))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 0.1"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:50], Y[:50], test_size=21, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 1"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:50], Y[:50], test_size=21, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""## No. of data in training set = 100, test = 43

### alpha = 0.01
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:100], Y[:100], test_size=43, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.01))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 0.05"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:100], Y[:100], test_size=43, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.05))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 0.1

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:100], Y[:100], test_size=43, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 1"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X[:100], Y[:100], test_size=43, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""## No. of data in training set = total

### alpha = 0.01
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=429, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.01))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 0.05"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=429, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.05))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 0.1"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=429, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

"""### alpha = 1"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Replace 'your_dataset.csv' with the actual file path
file_path = '/content/drive/MyDrive/Regression/UnivariateData/13.csv'

# Read the CSV file without header names
df = pd.read_csv(file_path, header=None)

# Extract X and Y columns
X = df.iloc[:, 0].values
Y = df.iloc[:, 1].values

# a. Training datasets of size 10 and testing data of size 3
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=429, random_state=42)

# b. Model complexity (degree of polynomial): 2 to 9
degrees = range(2, 10)

# Lists to store MSE values
mse_train_values = []
mse_test_values = []

# Function to fit and plot polynomial curve
def fit_and_plot(X_train, y_train, X_test, y_test, degree):
    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1))  # No regularization for simplicity
    model.fit(X_train.reshape(-1, 1), y_train)

    # Plotting
    plt.scatter(X_train, y_train, label='Training Data', color='blue')
    plt.scatter(X_test, y_test, label='Test Data', color='red', marker='x')

    x_range = np.linspace(min(X), max(X), 100)
    plt.plot(x_range, model.predict(x_range.reshape(-1, 1)), label=f'Degree {degree}', color='green')

    plt.title(f'Polynomial Fit (Degree {degree})')
    plt.legend()
    plt.show()

    # Calculate MSE for training and test data
    y_train_pred = model.predict(X_train.reshape(-1, 1))
    y_test_pred = model.predict(X_test.reshape(-1, 1))

    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    print(f'Degree {degree} - Training MSE: {mse_train}, Test MSE: {mse_test}')

    # Append MSE values to lists for later plotting
    mse_train_values.append(mse_train)
    mse_test_values.append(mse_test)

# Plotting for different degrees and calculating MSE
for degree in degrees:
    fit_and_plot(X_train, y_train, X_test, y_test, degree)

coefficient=[]
for degree in degrees:
    coefficient.append(np.polyfit(X_train, y_train, degree))

print("Coefficient",coefficient)

# Display Plots of the values of mean squared error (MSE) on training data and test data
plt.plot(degrees, mse_train_values, label='Training MSE', marker='o')
plt.plot(degrees, mse_test_values, label='Test MSE', marker='o')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Mean Squared Error vs. Model Complexity')
plt.legend()
plt.show()

